{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: pylab import has clobbered these variables: ['log', 'exp']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n"
     ]
    }
   ],
   "source": [
    "#Import Statements\n",
    "\n",
    "#basic\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import log,exp\n",
    "\n",
    "#visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "import seaborn\n",
    "\n",
    "% pylab inline\n",
    "\n",
    "#sklearn\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.metrics import mean_squared_error, confusion_matrix,accuracy_score, make_scorer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "#other stats\n",
    "from scipy import stats\n",
    "from patsy import dmatrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    \n",
    "    # Feature engineering for categorical variables captured as numbers\n",
    "    # Turn MSSubClass into factors\n",
    "    code = ['20', '30', '40', '45', '50', '60', '70', '75', '80', '85', '90', '120', '150', '160', '180', '190']\n",
    "    strings = ['1-STORY 1946 & NEWER ALL STYLES', '1-STORY 1945 & OLDER', '1-STORY W/FINISHED ATTIC ALL AGES', '1-1/2 STORY - UNFINISHED ALL AGES',\\\n",
    "     '1-1/2 STORY FINISHED ALL AGES', '2-STORY 1946 & NEWER', '2-STORY 1945 & OLDER', '2-1/2 STORY ALL AGES', \\\n",
    "     'SPLIT OR MULTI-LEVEL', 'SPLIT FOYER', 'DUPLEX - ALL STYLES AND AGES', '1-STORY PUD (Planned Unit Development) - 1946 & NEWER',\\\n",
    "     '1-1/2 STORY PUD - ALL AGES', '2-STORY PUD - 1946 & NEWER', 'PUD - MULTILEVEL - INCL SPLIT LEV/FOYER', \\\n",
    "     '2 FAMILY CONVERSION - ALL STYLES AND AGES']\n",
    "\n",
    "    MSSubClass=dict(zip(code,strings))\n",
    "    df['MSSubClass']=[MSSubClass[str(val)] for val in df['MSSubClass']]\n",
    "\n",
    "    # Turn month sold into factors\n",
    "    months = ['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sept','Oct','Nov','Dec']\n",
    "    df['MoSold'] = df['MoSold'].replace(to_replace = df['MoSold'].value_counts().index.sort_values(),value=months)\n",
    "    \n",
    "    # Feature engineering for age-related variables\n",
    "    # Convert yearsold vs yearbuilt into age of house\n",
    "    df['Age'] =  df['YrSold'] - df['YearBuilt']\n",
    "    df = df.drop('YearBuilt', 1)\n",
    "    # Convert yearsold vs. yearreomdadd into age of remodel. Adding 2 to eliminate any negative or 0 values\n",
    "    df['AgeRem'] = (df['YrSold'] - df['YearRemodAdd'])+2\n",
    "    df = df.drop('YearRemodAdd', 1)\n",
    "    # Remove age of garage - many missing values (if no garage)\n",
    "    #  no additional valuable information (garage captured in other variables); age of house more important for age\n",
    "    df = df.drop('GarageYrBlt', 1)\n",
    "   \n",
    "    # Fill select variables with most common / mode where logical\n",
    "    # Most masonry veneer type is None and area is 0\n",
    "    df['MasVnrType'] = df['MasVnrType'].fillna('None')\n",
    "    df['MasVnrArea'] = df['MasVnrArea'].fillna(0.0)\n",
    "    # Most electrical is 'SBrkr'\n",
    "    df['Electrical'] = df['Electrical'].fillna('SBrkr')\n",
    "    df['LotFrontage'] = df['LotFrontage'].fillna(mean(df['LotFrontage']))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_dummies(X_df):\n",
    "    # Dummify X data\n",
    "    X_dummy = pd.get_dummies(X_df,dummy_na=True)\n",
    "    return X_dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def level_cat(df_train,df_comp):\n",
    "    traincols = list(df_train.columns.values)\n",
    "    testcols = list(df_comp.columns.values)\n",
    "    \n",
    "    # Align train data columns to competition data columns\n",
    "    missingcols1 = list(set(testcols)-set(traincols))\n",
    "    for col in missingcols1:\n",
    "        df_train[col] = 0.0\n",
    "\n",
    "    # Align test data columns to competition data columns\n",
    "    missingcols = list(set(traincols)-set(testcols))\n",
    "    print len(missingcols)\n",
    "    for col in missingcols:\n",
    "        df_comp[col] = 0.0\n",
    "    df_comp = df_comp[traincols+missingcols1]\n",
    "    \n",
    "    return df_train,df_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "File train.csv does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-fe4abc4e7a04>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhousedata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'train.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m# Split into X and y\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhousedata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'SalePrice'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhousedata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'SalePrice'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Vishwa\\Anaconda2\\lib\\site-packages\\pandas\\io\\parsers.pyc\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    560\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    561\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 562\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    563\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    564\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Vishwa\\Anaconda2\\lib\\site-packages\\pandas\\io\\parsers.pyc\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 315\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    316\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    317\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mchunksize\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Vishwa\\Anaconda2\\lib\\site-packages\\pandas\\io\\parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    643\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 645\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    646\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    647\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Vishwa\\Anaconda2\\lib\\site-packages\\pandas\\io\\parsers.pyc\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m    797\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    798\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 799\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    800\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    801\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Vishwa\\Anaconda2\\lib\\site-packages\\pandas\\io\\parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1211\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'allow_leading_cols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1213\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_parser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1215\u001b[0m         \u001b[1;31m# XXX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader.__cinit__ (pandas\\parser.c:3427)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader._setup_parser_source (pandas\\parser.c:6861)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mIOError\u001b[0m: File train.csv does not exist"
     ]
    }
   ],
   "source": [
    "housedata = preprocess(pd.read_csv('train.csv'))\n",
    "# Split into X and y\n",
    "y = housedata['SalePrice']\n",
    "X = housedata.drop('SalePrice', 1)\n",
    "\n",
    "#preprocess and dummify competition\n",
    "X = get_dummies(X)\n",
    "competition = preprocess(pd.read_csv('test.csv'))\n",
    "X_comp = get_dummies(competition)\n",
    "\n",
    "X,X_comp = level_cat(X,X_comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.33, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Model Exploration\n",
    "Work that was done in APM HW 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run models\n",
    "#Linear Regression\n",
    "MLR =LinearRegression()\n",
    "model_MLR = MLR.fit(X_train,y_train)\n",
    "MLR_predict = model_MLR.predict(X_test)\n",
    "MLR_RMSE= sqrt(mean_squared_error(y_test, MLR_predict))\n",
    "print \"MLR RMSE:\",MLR_RMSE\n",
    "\n",
    "#get best λ with LassoCV\n",
    "lasso_cv = LassoCV(alphas=None, cv=10, max_iter=10000)\n",
    "model_cv = lasso_cv.fit(X_train,ravel(y_train))\n",
    "print \"Lasso CV best λ:\",model_cv.alpha_\n",
    "lasso_predict= model_cv.predict(X_test)\n",
    "lasso_RMSE= sqrt(mean_squared_error(y_test, lasso_predict))\n",
    "print \"Lasso RMSE:\",lasso_RMSE\n",
    "\n",
    "#get best λ with RidgeCV\n",
    "ridge_cv = RidgeCV(cv=10)\n",
    "ridge_model_cv = ridge_cv.fit(X_train,ravel(y_train))\n",
    "print \"Ridge CV best λ:\",ridge_model_cv.alpha_\n",
    "ridge_predict= ridge_model_cv.predict(X_test)\n",
    "ridge_RMSE= sqrt(mean_squared_error(y_test, ridge_predict))\n",
    "print \"Ridge RMSE:\",ridge_RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Model residuals\n",
    "\n",
    "MLRresiduals = y_test - MLR_predict\n",
    "lassoResiduals = y_test - lasso_predict\n",
    "ridgeResiduals = y_test - ridge_predict\n",
    "\n",
    "# Plot residuals\n",
    "fig = plt.figure(figsize=(15, 7))\n",
    "\n",
    "# Predicted vs. Actual\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax1.plot(y_test,MLR_predict,\"o\",label='MLR', color='darkblue')\n",
    "ax1.plot(y_test,lasso_predict,\"o\",label='Lasso',color='blue')\n",
    "ax1.plot(y_test,ridge_predict,\"o\",label='Ridge',color='aqua')\n",
    "ax1.legend(numpoints=1,loc='upper left')\n",
    "ax1.set_ylabel('Predicted Price ($)')\n",
    "ax1.yaxis.set_major_formatter(mtick.FuncFormatter('{:,.0f}'.format))\n",
    "ax1.set_xlabel('Actual Price ($)')\n",
    "ax1.xaxis.set_major_formatter(mtick.FuncFormatter('{:,.0f}'.format))\n",
    "ax1.set_title('Predicted vs. Actual Price', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Residuals\n",
    "ax2 = fig.add_subplot(122)\n",
    "ax2.plot(y_test,MLRresiduals,\"o\",label='MLR',color='darkblue')\n",
    "ax2.plot(y_test,lassoResiduals,\"o\",label='Lasso',color='blue')\n",
    "ax2.plot(y_test,ridgeResiduals,\"o\",label='Ridge',color='aqua')\n",
    "ax2.legend(numpoints=1,loc='upper left')\n",
    "ax2.set_ylabel('Residuals ($)')\n",
    "ax2.yaxis.set_major_formatter(mtick.FuncFormatter('{:,.0f}'.format))\n",
    "ax2.set_xlabel('Actual Price ($)')\n",
    "ax2.xaxis.set_major_formatter(mtick.FuncFormatter('{:,.0f}'.format))\n",
    "ax2.set_title('Residuals', fontsize=12, fontweight='bold')\n",
    "\n",
    "fig.subplots_adjust(wspace=.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Try predicting using log SalePrice\n",
    "log_y_train = y_train.map(float).map(log)\n",
    "log_y_test = y_test.map(float).map(log)\n",
    "\n",
    "#Linear Regression\n",
    "MLR =LinearRegression()\n",
    "model_MLR2 = MLR.fit(X_train,log_y_train)\n",
    "MLR_predict2 = model_MLR2.predict(X_test)\n",
    "MLR_RMSE2 = sqrt(mean_squared_error(y_test, np.exp(MLR_predict2)))\n",
    "print \"MLR RMSE:\",MLR_RMSE2\n",
    "\n",
    "#get best λ with LassoCV\n",
    "lasso_cv2 = LassoCV(alphas=None, cv=10, max_iter=10000)\n",
    "model_cv2 = lasso_cv2.fit(X_train,ravel(log_y_train))\n",
    "print \"Lasso CV best λ:\",model_cv2.alpha_\n",
    "lasso_predict2= model_cv2.predict(X_test)\n",
    "lasso_RMSE2 = sqrt(mean_squared_error(y_test, np.exp(lasso_predict2)))\n",
    "print \"Lasso RMSE:\",lasso_RMSE2\n",
    "\n",
    "#get best λ with RidgeCV\n",
    "ridge_cv2 = RidgeCV(cv=10)\n",
    "ridge_model_cv2 = ridge_cv2.fit(X_train,ravel(log_y_train))\n",
    "print \"Ridge CV best λ:\",ridge_model_cv2.alpha_\n",
    "ridge_predict2 = ridge_model_cv2.predict(X_test)\n",
    "ridge_RMSE2 = sqrt(mean_squared_error(y_test, np.exp(ridge_predict2)))\n",
    "print \"Ridge RMSE:\",ridge_RMSE2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#residuals with log price models (in original scale)\n",
    "MLRresiduals2 = y_test - np.exp(MLR_predict2)\n",
    "lassoResiduals2 = y_test - np.exp(lasso_predict2)\n",
    "ridgeResiduals2 = y_test - np.exp(ridge_predict2)\n",
    "\n",
    "# Plot residuals\n",
    "fig = plt.figure(figsize=(15, 7))\n",
    "\n",
    "# Predicted vs. Actual\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax1.plot(y_test,np.exp(MLR_predict2),\"o\",label='MLR',color='darkblue')\n",
    "ax1.plot(y_test,np.exp(lasso_predict2),\"o\",label='Lasso',color='blue')\n",
    "ax1.plot(y_test,np.exp(ridge_predict2),\"o\",label='Ridge',color='aqua')\n",
    "ax1.legend(numpoints=1,loc='upper left')\n",
    "ax1.set_ylabel('Predicted Price ($)')\n",
    "ax1.yaxis.set_major_formatter(mtick.FuncFormatter('{:,.0f}'.format))\n",
    "ax1.set_xlabel('Actual Price ($)')\n",
    "ax1.xaxis.set_major_formatter(mtick.FuncFormatter('{:,.0f}'.format))\n",
    "ax1.set_title('Predicted vs. Actual Price', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Residuals\n",
    "ax2 = fig.add_subplot(122)\n",
    "ax2.plot(y_test,MLRresiduals2,\"o\",label='MLR',color='darkblue')\n",
    "ax2.plot(y_test,lassoResiduals2,\"o\",label='Lasso',color='blue')\n",
    "ax2.plot(y_test,ridgeResiduals2,\"o\",label='Ridge',color='aqua')\n",
    "ax2.legend(numpoints=1,loc='upper left')\n",
    "ax2.set_ylabel('Residuals ($)')\n",
    "ax2.yaxis.set_major_formatter(mtick.FuncFormatter('{:,.0f}'.format))\n",
    "ax2.set_xlabel('Actual Price ($)')\n",
    "ax2.xaxis.set_major_formatter(mtick.FuncFormatter('{:,.0f}'.format))\n",
    "ax2.set_title('Residuals', fontsize=12, fontweight='bold')\n",
    "\n",
    "fig.subplots_adjust(wspace=.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Scale data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "y_scaler = StandardScaler()\n",
    "Y_scaled = ravel(y_scaler.fit_transform(y_train.reshape(-1, 1)))\n",
    "Y_test_scaled = ravel(y_scaler.transform(y_test.reshape(-1, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run MLP using different hidden layer sizes\n",
    "sizes = [(20,),(50,),(100,),(150,),(200,),(250,),(300,)]\n",
    "RMSEs = []\n",
    "for size in sizes:\n",
    "    MLP = MLPRegressor(hidden_layer_sizes = size,activation='tanh',solver='sgd',learning_rate='constant',random_state=42,\\\n",
    "                       batch_size=40,learning_rate_init=0.001)\n",
    "    model_MLP = MLP.fit(X_scaled,Y_scaled)\n",
    "    MLP_predict = model_MLP.predict(X_test_scaled)\n",
    "    MLP_RMSE= sqrt(mean_squared_error(y_test, y_scaler.inverse_transform(MLP_predict)))\n",
    "    RMSEs.append(MLP_RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Choosing hidden layer size with best RMSE\n",
    "MLP = MLPRegressor(hidden_layer_sizes = sizes[np.argmin(RMSEs)],activation='tanh',solver='sgd',learning_rate='constant',random_state=42,\\\n",
    "                   batch_size=40,learning_rate_init=0.001)\n",
    "model_MLP = MLP.fit(X_scaled,Y_scaled)\n",
    "MLP_predict = model_MLP.predict(X_test_scaled)\n",
    "MLP_RMSE = sqrt(mean_squared_error(y_test, y_scaler.inverse_transform(MLP_predict)))\n",
    "print \"MLP RMSE:\",MLP_RMSE\n",
    "\n",
    "MLPresiduals = y_test - y_scaler.inverse_transform(MLP_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot residuals\n",
    "fig = plt.figure(figsize=(15, 7))\n",
    "\n",
    "# Predicted vs. Actual\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax1.plot(y_test,y_scaler.inverse_transform(MLP_predict),\"o\",label='MLP',color='aliceblue')\n",
    "ax1.legend(numpoints=1,loc='upper left')\n",
    "ax1.set_ylabel('Predicted Price ($)')\n",
    "ax1.yaxis.set_major_formatter(mtick.FuncFormatter('{:,.0f}'.format))\n",
    "ax1.set_xlabel('Actual Price ($)')\n",
    "ax1.xaxis.set_major_formatter(mtick.FuncFormatter('{:,.0f}'.format))\n",
    "ax1.set_title('Predicted vs. Actual Price', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Residuals\n",
    "ax2 = fig.add_subplot(122)\n",
    "ax2.plot(y_test,MLPresiduals, \"o\",label='MLP',color='aliceblue')\n",
    "ax2.legend(numpoints=1,loc='upper left')\n",
    "ax2.set_ylabel('Residuals ($)')\n",
    "ax2.yaxis.set_major_formatter(mtick.FuncFormatter('{:,.0f}'.format))\n",
    "ax2.set_xlabel('Actual Price ($)')\n",
    "ax2.xaxis.set_major_formatter(mtick.FuncFormatter('{:,.0f}'.format))\n",
    "ax2.set_title('Residuals', fontsize=12, fontweight='bold')\n",
    "\n",
    "fig.subplots_adjust(wspace=.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Try Linear Regression, Lasso, and Ridge with scaled X data\n",
    "\n",
    "#Linear Regression\n",
    "MLR =LinearRegression(fit_intercept=False)\n",
    "model_MLR1 = MLR.fit(X_scaled,y_train)\n",
    "MLR_predict1 = model_MLR1.predict(X_test_scaled)\n",
    "MLR_RMSE1= sqrt(mean_squared_error(y_test, MLR_predict1))\n",
    "print \"MLR RMSE:\",MLR_RMSE1\n",
    "\n",
    "#get best λ with LassoCV\n",
    "lasso_cv1 = LassoCV(alphas=None, cv=10, max_iter=10000)\n",
    "model_cv1 = lasso_cv1.fit(X_scaled,ravel(y_train))\n",
    "print \"Lasso CV best λ:\",model_cv1.alpha_\n",
    "lasso_predict1= model_cv1.predict(X_test_scaled)\n",
    "lasso_RMSE1= sqrt(mean_squared_error(y_test, lasso_predict1))\n",
    "print \"Lasso RMSE:\",lasso_RMSE1\n",
    "\n",
    "#get best λ with RidgeCV\n",
    "ridge_cv1 = RidgeCV(cv=10)\n",
    "ridge_model_cv1 = ridge_cv1.fit(X_scaled,ravel(y_train))\n",
    "print \"Ridge CV best λ:\",ridge_model_cv1.alpha_\n",
    "ridge_predict1= ridge_model_cv1.predict(X_test_scaled)\n",
    "ridge_RMSE1= sqrt(mean_squared_error(y_test, ridge_predict1))\n",
    "print \"Ridge RMSE:\",ridge_RMSE1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Based on RMSE, it appears as though MLR may have challenges predicting this data\n",
    "# For example, the linear regression problem could be under-determined \n",
    "#  (where the number of linearly independent rows of the training matrix \n",
    "#    is less than its number of linearly independent columns),\n",
    "#  resulting in erroneous predictions\n",
    "\n",
    "# Graph to see\n",
    "MLRresiduals1 = y_test - MLR_predict1\n",
    "fig = plt.figure(figsize=(15, 7))\n",
    "\n",
    "# Predicted vs. Actual\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax1.plot(y_test,MLR_predict1,\"o\",label='MLR',color='darkblue')\n",
    "ax1.legend(numpoints=1,loc='upper left')\n",
    "ax1.set_ylabel('Predicted Price ($)')\n",
    "ax1.set_xlabel('Actual Price ($)')\n",
    "ax1.xaxis.set_major_formatter(mtick.FuncFormatter('{:,.0f}'.format))\n",
    "ax1.set_title('Predicted vs. Actual Price', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Residuals\n",
    "ax2 = fig.add_subplot(122)\n",
    "ax2.plot(y_test,MLRresiduals1, \"o\",label='MLR',color='darkblue')\n",
    "ax2.legend(numpoints=1,loc='upper left')\n",
    "ax2.set_ylabel('Residuals ($)')\n",
    "ax2.set_xlabel('Actual Price ($)')\n",
    "ax2.xaxis.set_major_formatter(mtick.FuncFormatter('{:,.0f}'.format))\n",
    "ax2.set_title('Residuals', fontsize=12, fontweight='bold')\n",
    "\n",
    "fig.subplots_adjust(wspace=.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot Lasso and Ridge\n",
    "lassoResiduals1 = y_test - lasso_predict1\n",
    "ridgeResiduals1 = y_test - ridge_predict1\n",
    "\n",
    "fig = plt.figure(figsize=(15, 7))\n",
    "\n",
    "# Predicted vs. Actual\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax1.plot(y_test,lasso_predict1,\"o\",label='Lasso',color='blue')\n",
    "ax1.plot(y_test,ridge_predict1,\"o\",label='Ridge',color='aqua')\n",
    "ax1.legend(numpoints=1,loc='upper left')\n",
    "ax1.set_ylabel('Predicted Price ($)')\n",
    "ax1.yaxis.set_major_formatter(mtick.FuncFormatter('{:,.0f}'.format))\n",
    "ax1.set_xlabel('Actual Price ($)')\n",
    "ax1.xaxis.set_major_formatter(mtick.FuncFormatter('{:,.0f}'.format))\n",
    "ax1.set_title('Predicted vs. Actual Price', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Residuals\n",
    "ax2 = fig.add_subplot(122)\n",
    "ax2.plot(y_test,lassoResiduals1,\"o\",label='Lasso',color='blue')\n",
    "ax2.plot(y_test,ridgeResiduals1,\"o\",label='Ridge',color='aqua')\n",
    "ax2.legend(numpoints=1,loc='upper left')\n",
    "ax2.set_ylabel('Residuals ($)')\n",
    "ax2.yaxis.set_major_formatter(mtick.FuncFormatter('{:,.0f}'.format))\n",
    "ax2.set_xlabel('Actual Price ($)')\n",
    "ax2.xaxis.set_major_formatter(mtick.FuncFormatter('{:,.0f}'.format))\n",
    "ax2.set_title('Residuals', fontsize=12, fontweight='bold')\n",
    "\n",
    "fig.subplots_adjust(wspace=.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Try fitting on scaled data and log SalePrice for Lasso and Ridge\n",
    "#get best λ with LassoCV\n",
    "lasso_cv3 = LassoCV(alphas=None, cv=10, max_iter=10000)\n",
    "model_cv3 = lasso_cv3.fit(X_scaled,ravel(log_y_train))\n",
    "print \"Lasso CV best λ:\",model_cv3.alpha_\n",
    "lasso_predict3= model_cv3.predict(X_test_scaled)\n",
    "lasso_RMSE3 = sqrt(mean_squared_error(y_test, np.exp(lasso_predict3)))\n",
    "print \"Lasso RMSE:\",lasso_RMSE3\n",
    "\n",
    "#get best λ with RidgeCV\n",
    "ridge_cv3 = RidgeCV(cv=10)\n",
    "ridge_model_cv3 = ridge_cv3.fit(X_scaled,ravel(log_y_train))\n",
    "print \"Ridge CV best λ:\",ridge_model_cv3.alpha_\n",
    "ridge_predict3= ridge_model_cv3.predict(X_test_scaled)\n",
    "ridge_RMSE3 = sqrt(mean_squared_error(y_test, np.exp(ridge_predict3)))\n",
    "print \"Ridge RMSE:\",ridge_RMSE3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot Lasso and Ridge results for scaled X data / log SalePrice\n",
    "lassoResiduals3 = y_test - np.exp(lasso_predict3)\n",
    "ridgeResiduals3 = y_test - np.exp(ridge_predict3)\n",
    "\n",
    "fig = plt.figure(figsize=(15, 7))\n",
    "\n",
    "# Predicted vs. Actual\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax1.plot(y_test,np.exp(lasso_predict3),\"o\",label='Lasso',color='blue')\n",
    "ax1.plot(y_test,np.exp(ridge_predict3),\"o\",label='Ridge',color='aqua')\n",
    "ax1.legend(numpoints=1,loc='upper left')\n",
    "ax1.set_ylabel('Predicted Price ($)')\n",
    "ax1.yaxis.set_major_formatter(mtick.FuncFormatter('{:,.0f}'.format))\n",
    "ax1.set_xlabel('Actual Price ($)')\n",
    "ax1.xaxis.set_major_formatter(mtick.FuncFormatter('{:,.0f}'.format))\n",
    "ax1.set_title('Predicted vs. Actual Price', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Residuals\n",
    "ax2 = fig.add_subplot(122)\n",
    "ax2.plot(y_test,lassoResiduals3,\"o\",label='Lasso',color='blue')\n",
    "ax2.plot(y_test,ridgeResiduals3,\"o\",label='Ridge',color='aqua')\n",
    "ax2.legend(numpoints=1,loc='upper left')\n",
    "ax2.set_ylabel('Residuals ($)')\n",
    "ax2.yaxis.set_major_formatter(mtick.FuncFormatter('{:,.0f}'.format))\n",
    "ax2.set_xlabel('Actual Price ($)')\n",
    "ax2.xaxis.set_major_formatter(mtick.FuncFormatter('{:,.0f}'.format))\n",
    "ax2.set_title('Residuals', fontsize=12, fontweight='bold')\n",
    "\n",
    "fig.subplots_adjust(wspace=.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best = SVR(kernel='linear', C=10)\n",
    "best.fit(X_train,y_train)\n",
    "predictions=best.predict(X_test)\n",
    "np.sqrt(mean_squared_error(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters = {'loss': ['squared_loss', 'huber'],\n",
    "             'penalty': ['l1','l2'],\n",
    "              \n",
    "             }\n",
    "accuracy=make_scorer(mean_squared_error, greater_is_better=False)\n",
    "clf2 = GridSearchCV(SGDRegressor(random_state=42), parameters, cv=5,scoring=accuracy)\n",
    "clf2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print clf2.best_params_\n",
    "print clf2.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best2 = SGDRegressor(loss='huber', penalty='l2',random_state=42)\n",
    "best2.fit(X_train, y_train)\n",
    "pred = best2.predict(X_test)\n",
    "np.sqrt(mean_squared_error(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
